{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 3: Comparando clasificadores\n",
    "Integrantes del equipo:\n",
    "- Francisco Arenas\n",
    "- Víctor Curiel\n",
    "- Víctor Rodríguez\n",
    "- Alek Howland\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASE DE VALIDACION\n",
      "-KNN\n",
      "Con k = 1 tenemos un accuracy de 0.96\n",
      "Con k = 2 tenemos un accuracy de 0.9466666666666667\n",
      "Con k = 3 tenemos un accuracy de 0.9466666666666667\n",
      "Con k = 4 tenemos un accuracy de 0.9733333333333334\n",
      "Con k = 5 tenemos un accuracy de 0.96\n",
      "Con k = 6 tenemos un accuracy de 0.96\n",
      "Con k = 7 tenemos un accuracy de 0.96\n",
      "Con k = 8 tenemos un accuracy de 0.96\n",
      "Con k = 9 tenemos un accuracy de 0.96\n",
      "Con k = 10 tenemos un accuracy de 0.96\n",
      "Con k = 1 obtenemos el mejor accuracy\n",
      "-SVM\n",
      "Con el kernel linear tenemos un accuracy de 0.96\n",
      "Con el kernel rbf tenemos un accuracy de 0.96\n",
      "El kernel con el que obtenemos un mayor accuracy es rbf\n",
      "FASE DE PRUEBAS\n",
      "KNN: 1.0\n",
      "J48: 0.9733333333333334\n",
      "SVM: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Leemos csv\n",
    "data = pd.read_csv('iris.csv')\n",
    "#Eliminamos la columna de Id\n",
    "data = data.drop(columns=[\"Id\"])\n",
    "\n",
    "#Creamos instancia para el clasificador de Árbol de decisión\n",
    "dTreeClassifier = DecisionTreeClassifier()\n",
    "#Creamos instancia para el clasificador de KNN\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=10)\n",
    "#Creamos instancia para el clasificador de SVM\n",
    "svmClassifier = svm.SVC()\n",
    "\n",
    "#Separamos en datos y etiquetas\n",
    "X = data.iloc[:, :-1].to_numpy() #todas las filas, todas las columnas menos la última\n",
    "Y = data.iloc[:, -1].to_numpy() #todas las filas, sólo la última columna\n",
    "\n",
    "#Obtener datos de entrenamiento y de pruebas\n",
    "xTrain, xTest, yTrain, yTest = model_selection.train_test_split(X, Y, test_size=0.5) #test size es un %\n",
    "#Del conjunto de pruebas obtener el conjunto de validación\n",
    "xValidation, xTest, yValidation, yTest = model_selection.train_test_split(X, Y, test_size=0.5) \n",
    "\n",
    "#normalizar para SVM\n",
    "normalizer = preprocessing.MinMaxScaler() #generar normalizador\n",
    "normalizer = normalizer.fit(xTrain) #sólo hacer la normalización/estandarización con los datos de entrenamiento\n",
    "xTrainNew = normalizer.transform(xTrain)\n",
    "\n",
    "#transformar datos de validación y pruebas\n",
    "xTestNew = normalizer.transform(xTest)\n",
    "xValidationNew = normalizer.transform(xValidation)\n",
    "\n",
    "# -ENTRENAMIENTO Y VALIDACIÓN-\n",
    "print(\"FASE DE VALIDACION\")\n",
    "# KNN\n",
    "#Probaremos con valores de k del 1 al 10 para determinar qué valor nos da un mayor accuracy\n",
    "print(\"-KNN\")\n",
    "bestKValue = 0\n",
    "for k in range(1, 11): # valores de k para el proceso de validación del KNN\n",
    "    knnClassifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    knnClassifier = knnClassifier.fit(xTrain, yTrain)\n",
    "    acc = accuracy_score(yValidation, knnClassifier.predict(xValidation))\n",
    "    if acc > bestKValue:\n",
    "        bestKValue = k\n",
    "    print(\"Con k = \" + str(k) + \" tenemos un accuracy de \" + str(acc))\n",
    "print(\"Con k = \" + str(bestKValue) + \" obtenemos el mejor accuracy\")\n",
    "\n",
    "# SVM\n",
    "#Probaremos con diferentes kernels para determinar qué valor nos da un mayor accuracy\n",
    "print(\"-SVM\")\n",
    "kernels = [\"linear\", \"rbf\"]\n",
    "bestSVMAccuracy = -1\n",
    "for k in kernels: # valores de k para el proceso de validación del KNN\n",
    "    svmClassifier = svm.SVC(kernel=k)\n",
    "    svmClassifier = svmClassifier.fit(xTrainNew, yTrain)\n",
    "    acc = accuracy_score(yValidation, svmClassifier.predict(xValidationNew))\n",
    "    if acc > bestSVMAccuracy:\n",
    "        bestSVMAccuracy = kernels.index(k)\n",
    "    print(\"Con el kernel \" + str(k) + \" tenemos un accuracy de \" + str(acc))\n",
    "print(\"El kernel con el que obtenemos un mayor accuracy es \" + kernels[bestSVMAccuracy])\n",
    "\n",
    "# Árboles de decisión - J48\n",
    "dTreeClassifier = DecisionTreeClassifier()\n",
    "dTreeClassifier = dTreeClassifier.fit(xTrain,yTrain)\n",
    "\n",
    "print(\"FASE DE PRUEBAS\")\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=bestKValue)\n",
    "knnClassifier = knnClassifier.fit(xTrain, yTrain)\n",
    "print(\"KNN: \" + str(accuracy_score(yTest, knnClassifier.predict(xTest))))\n",
    "print(\"J48: \" + str(accuracy_score(yTest, dTreeClassifier.predict(xTest))))\n",
    "svmClassifier = svm.SVC(kernel=kernels[bestSVMAccuracy])\n",
    "svmClassifier = svmClassifier.fit(xTrainNew, yTrain)\n",
    "print(\"SVM: \" + str(accuracy_score(yTest, svmClassifier.predict(xTestNew))))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbb303e5cb88e7038ec3bc0743ef90678fa91244e060eff79bcd7ba139b6f1e6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('applesenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
